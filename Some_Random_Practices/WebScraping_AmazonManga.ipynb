{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "301e6160-b01e-4852-a364-9ad76e51715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bb3bac5-ebcd-474e-a8ff-81355b24d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Function for extracting different data from web page.\n",
    "\n",
    "def get_title(soup): \n",
    "    try: \n",
    "        title_value = soup.find(\"span\", attrs={\"id\": \"productTitle\"}).text.strip()\n",
    "    except AttributeError:\n",
    "        title_value = \"\"\n",
    "\n",
    "    return title_value\n",
    "\n",
    "def get_price(soup): \n",
    "    try: \n",
    "        price_value = soup.find(\"span\", attrs={\"class\": \"a-size-base a-color-price a-color-price\"}).text.strip()\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            # If there is some deal price\n",
    "            price = soup.find(\"span\", attrs={'class':'a-size-base a-color-price a-color-price'}).text.strip()\n",
    "\n",
    "        except:\n",
    "            price_value = \"\"\n",
    "\n",
    "    return price_value\n",
    "\n",
    "def get_author(soup): \n",
    "    try: \n",
    "        author_value = soup.find(\"span\", attrs={\"class\": \"author notFaded\"}).find(\"a\", attrs={\"class\": \"a-link-normal\"}).text.strip()\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            # If there is some deal price\n",
    "            author_value = soup.find(\"span\", attrs={'class':'author notFaded'}).find(\"a\", attrs={\"class\": \"a-link-normal\"}).text.strip()\n",
    "\n",
    "        except:\n",
    "            author_value = \"\"\n",
    "    \n",
    "    return author_value\n",
    "\n",
    "def get_rating(soup): \n",
    "    try:\n",
    "        rating_value = soup.find(\"a\", attrs={\"class\": \"a-popover-trigger a-declarative\"}).find(\"span\", attrs={\"class\": \"a-size-base a-color-base\"}).text.strip()\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            # If there is some deal price\n",
    "            rating_value = soup.find(\"a\", attrs={\"class\": \"a-popover-trigger a-declarative\"}).find(\"span\", attrs={\"class\": \"a-size-base a-color-base\"}).text.strip()\n",
    "\n",
    "        except:\n",
    "            rating_value = \"\"\n",
    "    \n",
    "    return rating_value\n",
    "\n",
    "def get_stockAvailable(soup): \n",
    "    try:\n",
    "        stock_value = soup.find(\"div\", attrs={\"id\": \"availability\"}).find(\"span\").text.strip().text.strip()\n",
    "    except AttributeError:\n",
    "            stock_value = \"Not Available\"\t\n",
    "\n",
    "    return stock_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e64275be-3401-4061-8ea8-1df0bc55f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__': \n",
    "\n",
    "    ##URL \n",
    "    url = \"https://www.amazon.in/s?k=Manga&crid=YGLUF5F6F0M9&sprefix=manga%2Caps%2C293&ref=nb_sb_noss_2\"\n",
    "    \n",
    "    ##Header \n",
    "    headers = ({'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36', 'Accept-Language': 'en-us, en;q=0.5'})\n",
    "\n",
    "    #HTTP request\n",
    "    webpage = requests.get(url, headers=headers)\n",
    "\n",
    "    ##Soup object for containing all the data\n",
    "    soup = BeautifulSoup(webpage.content, 'html.parser')\n",
    "\n",
    "    ##All manga links saved here\n",
    "    links = soup.find_all(\"a\", attrs={\"class\": \"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"})\n",
    "\n",
    "    ## New list to save each link\n",
    "    links_list = []\n",
    "    \n",
    "    ## Saving each product links in the new list\n",
    "    for link in links:\n",
    "        links_list.append(link.get('href'))\n",
    "\n",
    "    allDataVariables = {'title':[], 'author':[], 'rating':[], 'price':[], 'available':[]}\n",
    "\n",
    "    ## Looping for extracting product data from the web page\n",
    "    for link in links_list:\n",
    "        new_webpage = requests.get('https://www.amazon.in' + link, headers=headers)\n",
    "        new_soup = BeautifulSoup(new_webpage.content, 'html.parser')\n",
    "\n",
    "        ## calling methods for extracting each data from the web page\n",
    "        allDataVariables['title'].append(get_title(new_soup))\n",
    "        allDataVariables['author'].append(get_author(new_soup))\n",
    "        allDataVariables['rating'].append(get_rating(new_soup))\n",
    "        allDataVariables['price'].append(get_price(new_soup))\n",
    "        allDataVariables['available'].append(get_stockAvailable(new_soup))\n",
    "\n",
    "    manga_df = pd.DataFrame.from_dict(allDataVariables)\n",
    "    manga_df['title'].replace('', np.nan, inplace=True)\n",
    "    manga_df = manga_df.dropna(subset=['title'])\n",
    "    manga_df.to_csv(\"csv_files\manga_data.csv\", header=True, index=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
